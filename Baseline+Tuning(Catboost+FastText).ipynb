{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd8bdac",
   "metadata": {},
   "source": [
    "# Описание задачи\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5483bab",
   "metadata": {},
   "source": [
    "Ссылка на данные: https://ods.ai/competitions/nlp-receipts/data\n",
    "\n",
    "Данные чеков ОФД содержат детальную информацию о тратах клиентов. Они помогают улучшать качество моделей кредитного скоринга и склонности к банковским продуктам, а также улучшать пользовательский опыт за счет структуризации трат клиентов в мобильном приложении. Однако работа с этим источником затрудняется его неструктурированностью: вся информация о купленном товаре лежит в одной строке произвольного формата.\n",
    "\n",
    "В предположении что каждая чековая позиция описывает какой-либо товар, наименование этого товара, а также его бренд, являются главной информацией, которую можно извлечь из чека. По итогу задача структуризации этих данных ограничивается выделением и нормализацией брендов и товаров.\n",
    "\n",
    "Участникам соревнования предоставляются два датасета с чековыми позициями, размеченный и неразмеченный:\n",
    "\n",
    "В размеченном датасете для каждой чековой позиции указаны нормализованные бренды и товары входящие в нее в исходном виде.\n",
    "В неразмеченном датасете даны только сами чековые позиции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f07c58",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f00d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RAND = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0dc8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_supervised_path = 'data/train_supervised_dataset.csv'\n",
    "train_unsupervised_path = 'data/train_unsupervised_dataset.csv'\n",
    "test_path = 'data/test_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e037d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sup = pd.read_csv(train_supervised_path).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051b03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsup = pd.read_csv(train_unsupervised_path).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91ec9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_path).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e7bc4",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de051803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Чистит текст\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    #text = re.sub(r'[^\\sa-zA-Z0-9@\\[\\]]',' ',text) # удаляет пунктцацию\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text) # удаляет цифры\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text) # удаляет знаки\n",
    "    text = re.sub(r'\\b\\S{1}\\b', '', text) # удаляет слова из 1-й буквы\n",
    "    text = re.sub(r'\\b\\S{2}\\b', '', text) # удаляет слова из 2-х букв\n",
    "    text = re.sub('\\s{2,}', \" \", text) # удаляет ненужные пробелы\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_sup['name'] = df_sup['name'].apply(clean_text)\n",
    "df_unsup['name'] = df_unsup['name'].apply(clean_text)\n",
    "df_test['name'] = df_test['name'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b8a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизирует\n",
    "df_sup['tokens'] = df_sup['name'].str.lower().str.split()\n",
    "df_unsup['tokens'] = df_unsup['name'].str.lower().str.split()\n",
    "df_test[\"tokens\"] = df_test[\"name\"].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de28604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_unsup, df_test, df_sup.drop(['good', 'brand'], axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81dc30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bio_tagging(row: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    По токенам чека и разметке (то есть выделенным товарам и брендам) строит BIO-теги\n",
    "    \"\"\"\n",
    "    tokens = row[\"tokens\"]\n",
    "    good = row[\"good\"].split(',')[0].split()\n",
    "    brand = row[\"brand\"].split(',')[0].split()\n",
    "    tags = ['O'] * len(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if len(good) > 0 and tokens[i:i + len(good)] == good:\n",
    "            tags[i] = \"B-GOOD\"\n",
    "            for j in range(i + 1, i + len(good)):\n",
    "                tags[j] = \"I-GOOD\"\n",
    "        if len(brand) > 0 and tokens[i:i + len(brand)] == brand:\n",
    "            tags[i] = \"B-BRAND\"\n",
    "            for j in range(i + 1, i + len(brand)):\n",
    "                tags[j] = \"I-BRAND\"\n",
    "                \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbfa07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sup[\"tags\"] = df_sup.apply(apply_bio_tagging, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e683c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fst_model = FastText(df['tokens'],\n",
    "                     vector_size=300,\n",
    "                     window=3,\n",
    "                     min_count=1,\n",
    "                     sg=1,\n",
    "                     alpha=0.1,\n",
    "                     negative=10,\n",
    "                     epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_series(column: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Преобразует столбец в необходимый вид\n",
    "    \"\"\"\n",
    "    token_list = column.to_list()\n",
    "    flat_list = [item for sublist in token_list for item in sublist]\n",
    "    tokens_series = pd.Series(flat_list)\n",
    "    \n",
    "    return tokens_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbbf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создает новые датафреймы, на основе векторов и BIO-тегов\n",
    "    \"\"\"\n",
    "    tags = to_series(df_sup[\"tags\"])\n",
    "    tokenss = to_series(df_sup[\"tokens\"])\n",
    "    dataset = tokenss.apply(lambda x: fst_model.wv[x])\n",
    "    dtv_train = pd.concat([pd.DataFrame(dataset.to_list()), \n",
    "           pd.DataFrame(tags)], axis=1, ignore_index=True)\n",
    "    dtv_train.rename(columns={300:\"labels\"}, inplace=True)\n",
    "\n",
    "    good_train = dtv_train.loc[dtv_train['labels'].isin([\"B-GOOD\", \"I-GOOD\", \"O\"])]\n",
    "    brand_train = dtv_train.loc[dtv_train['labels'].isin([\"B-BRAND\", \"I-BRAND\", \"O\"])]\n",
    "    \n",
    "    return good_train, brand_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd86fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_train, brand_train = make_datasets(df_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade2d01",
   "metadata": {},
   "source": [
    "# Modeling (Catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39b8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_good = good_train.drop(\"labels\", axis=1)\n",
    "y_good = good_train.labels\n",
    "\n",
    "X_brand = brand_train.drop(\"labels\", axis=1)\n",
    "y_brand = brand_train.labels\n",
    "\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_good,\n",
    "                                                            y_good,\n",
    "                                                            test_size=0.2,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=RAND)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_brand,\n",
    "                                                            y_brand,\n",
    "                                                            test_size=0.2,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=RAND)\n",
    "\n",
    "eval_set_g = [(X_test_g, y_test_g)]\n",
    "eval_set_b = [(X_test_b, y_test_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_g = CatBoostClassifier(random_state=RAND,\n",
    "                           eval_metric='TotalF1',\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "clf_b = CatBoostClassifier(random_state=RAND,\n",
    "                           eval_metric='TotalF1',\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "clf_g.fit(X_train_g,\n",
    "          y_train_g,\n",
    "          eval_set=eval_set_g,\n",
    "          early_stopping_rounds=100, \n",
    "          use_best_model=True,\n",
    "          verbose=False)\n",
    "\n",
    "clf_b.fit(X_train_b,\n",
    "          y_train_b,\n",
    "          eval_set=eval_set_b,\n",
    "          early_stopping_rounds=100, \n",
    "          use_best_model=True,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86ab87",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2527e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'learning_rate': np.linspace(0.01, 0.1, 5),\n",
    "    #'boosting_type' : ['Ordered', 'Plain'],\n",
    "    #'max_depth': list(range(3, 12)),\n",
    "    #'l2_leaf_reg': np.logspace(-5, 2, 5),\n",
    "    #'random_strength': list(range(10, 50, 5)),\n",
    "    #'bootstrap_type': [\"Bayesian\", \"Bernoulli\", \"MVS\", \"No\"],\n",
    "    #'border_count': [128, 254],\n",
    "    #'grow_policy': [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"],\n",
    "    'random_state': [RAND]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c94f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = CatBoostClassifier(random_state=RAND,\n",
    "                             eval_metric='TotalF1',\n",
    "                             loss_function='MultiClass',\n",
    "                             silent=True)\n",
    "grid_search_result_g = model_g.randomized_search(grid,\n",
    "                                              X=X_train_g,\n",
    "                                              y=y_train_g, \n",
    "                                              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = CatBoostClassifier(random_state=RAND,\n",
    "                             eval_metric='TotalF1',\n",
    "                             loss_function='MultiClass',\n",
    "                             silent=True)\n",
    "grid_search_result_b = model_b.randomized_search(grid,\n",
    "                                              X=X_train_b,\n",
    "                                              y=y_train_b, \n",
    "                                              verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77722987",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_best_g = grid_search_result_g['params']\n",
    "cat_best_b = grid_search_result_b['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_grid_g = CatBoostClassifier(**cat_best_g,\n",
    "                                eval_metric='TotalF1')\n",
    "\n",
    "cat_grid_b = CatBoostClassifier(**cat_best_b,\n",
    "                                eval_metric='TotalF1')\n",
    "\n",
    "cat_grid_g.fit(X_train_g,\n",
    "               y_train_g,\n",
    "               eval_set=eval_set_g,\n",
    "               early_stopping_rounds=100, \n",
    "               use_best_model=True,\n",
    "               verbose=False)\n",
    "\n",
    "cat_grid_b.fit(X_train_b,\n",
    "               y_train_b,\n",
    "               eval_set=eval_set_b,\n",
    "               early_stopping_rounds=100, \n",
    "               use_best_model=True,\n",
    "               verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a8026",
   "metadata": {},
   "source": [
    "# Create submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db92011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_good(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Формирует предсказания товаров\n",
    "    :param row: токены\n",
    "    :return: предсказанные товары\n",
    "    \"\"\"\n",
    "    good = []\n",
    "\n",
    "    for i in row:\n",
    "        try:\n",
    "            word_array = fst_model.wv[i]\n",
    "            dataset = pd.DataFrame(word_array.reshape((1, 300)))\n",
    "            pred = clf_g.predict(dataset)\n",
    "            if pred[0][0] == \"B-GOOD\":\n",
    "                good.append(i)\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "    \n",
    "    return ''.join(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc12453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit_brand(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Формирует предсказания брендов\n",
    "    :param row: токены\n",
    "    :return: предсказанные бренды\n",
    "    \"\"\"    \n",
    "    \n",
    "    brand = []\n",
    "\n",
    "    for i in row:\n",
    "        try:\n",
    "            word_array = fst_model.wv[i]\n",
    "            dataset = pd.DataFrame(word_array.reshape((1, 300)))\n",
    "            pred = clf_b.predict(dataset)\n",
    "            if pred[0][0] == \"B-BRAND\":\n",
    "                brand.append(i)\n",
    "        except Exception as ex:\n",
    "            pass\n",
    "    \n",
    "    return ''.join(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de61ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"good\"] = df_test[\"tokens\"].apply(create_submit)\n",
    "df_test[\"brand\"] = df_test[\"tokens\"].apply(create_submit_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = df_test.drop(['name', 'tokens'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('itog.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
